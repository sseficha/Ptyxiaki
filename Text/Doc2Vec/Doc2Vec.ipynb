{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pckgs.helper import EpochLogger\n",
    "from pckgs.headline_preprocess import HeadlinePreprocess\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pandarallel import pandarallel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import logging\n",
    "# import os\n",
    "# logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-2923817a18f1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#PREPROCESS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../datasets/223k crypto news headlines. Dataset. BDCenter Digital.csv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mHeadlinePreprocess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpreprocess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbigrams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Ptyxiaki/pckgs/headline_preprocess.py\u001B[0m in \u001B[0;36mpreprocess\u001B[0;34m(df, bigrams, tokenize)\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0;31m# tokenize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtokenize\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m             \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mword\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mword\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mword_tokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m         \u001B[0;31m# get bigrams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mbigrams\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, arg, na_action)\u001B[0m\n\u001B[1;32m   3981\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3982\u001B[0m         \"\"\"\n\u001B[0;32m-> 3983\u001B[0;31m         \u001B[0mnew_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mna_action\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mna_action\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3984\u001B[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001B[1;32m   3985\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"map\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/core/base.py\u001B[0m in \u001B[0;36m_map_values\u001B[0;34m(self, mapper, na_action)\u001B[0m\n\u001B[1;32m   1158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1159\u001B[0m         \u001B[0;31m# mapper is a function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1160\u001B[0;31m         \u001B[0mnew_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmap_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1162\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mnew_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/Ptyxiaki/pckgs/headline_preprocess.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0;31m# tokenize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtokenize\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m             \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mword\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mword\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mword_tokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m         \u001B[0;31m# get bigrams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mbigrams\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Ptyxiaki/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001B[0m in \u001B[0;36mword_tokenize\u001B[0;34m(text, language, preserve_line)\u001B[0m\n\u001B[1;32m    128\u001B[0m     \"\"\"\n\u001B[1;32m    129\u001B[0m     \u001B[0msentences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpreserve_line\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0msent_tokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m     return [\n\u001B[0m\u001B[1;32m    131\u001B[0m         \u001B[0mtoken\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msentences\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_treebank_word_tokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m     ]\n",
      "\u001B[0;32m~/anaconda3/envs/Ptyxiaki/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    129\u001B[0m     \u001B[0msentences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpreserve_line\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0msent_tokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m     return [\n\u001B[0;32m--> 131\u001B[0;31m         \u001B[0mtoken\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msentences\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_treebank_word_tokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    132\u001B[0m     ]\n",
      "\u001B[0;32m~/anaconda3/envs/Ptyxiaki/lib/python3.8/site-packages/nltk/tokenize/destructive.py\u001B[0m in \u001B[0;36mtokenize\u001B[0;34m(self, text, convert_parentheses, return_str)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mregexp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubstitution\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPUNCTUATION\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mregexp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubstitution\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0;31m# Handles parentheses.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#PREPROCESS\n",
    "df = pd.read_csv('../datasets/223k crypto news headlines. Dataset. BDCenter Digital.csv', header=0)\n",
    "df = HeadlinePreprocess.preprocess(df, bigrams=True, tokenize=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#see number of headlines per day\n",
    "import plotly.express as px\n",
    "\n",
    "temp = pd.read_csv('../datasets/223k crypto news headlines. Dataset. BDCenter Digital.csv', header=0)\n",
    "temp.rename(columns = {'publishdate':'date'}, inplace=True)\n",
    "temp.rename(columns = {'headlinetext':'text'}, inplace=True)\n",
    "temp.date = temp.date.map(lambda p: datetime.strptime(str(p), '%Y%m%d'))\n",
    "temp = temp.groupby('date').count()\n",
    "print(temp.describe())\n",
    "fig = px.bar(temp, x=temp.index, y='text', color='text')\n",
    "fig.show()\n",
    "# plt.figure()\n",
    "# sb.barplot(x = temp.index, y=temp.text)\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#build tagged documents and assign pandas id as doc id\n",
    "documents = [TaggedDocument(words = df.loc[i,'text'], tags=[df.index[i]]) for i in range(len(df))]\n",
    "\n",
    "epoch_logger = EpochLogger(documents)\n",
    "model = Doc2Vec(dm=1,\n",
    "                min_count=20,\n",
    "                window=2,\n",
    "                vector_size=300,\n",
    "                workers=3,\n",
    "                epochs=25,\n",
    "                seed=23)\n",
    "                # ,callbacks=[epoch_logger]\n",
    "\n",
    "#build vocabulary from documents\n",
    "model.build_vocab(documents, progress_per=10000)\n",
    "\n",
    "#train model\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "# temp_path = get_tmpfile('toy_d2v')\n",
    "# model = Doc2Vec.load(temp_path)\n",
    "#save model\n",
    "# model.save('vectors.kv')\n",
    "# model = Doc2Vec.load('vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=55769), Label(value='0 / 55769')))…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a5fa3808ec84cf9b0ae9a6f8e93ce44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 0         1         2         3         4         5    \\\ndate                                                                     \n2017-07-07  0.045714 -0.001961  0.025097  0.050116  0.124880  0.012416   \n2017-10-16  0.056051 -0.048256  0.014275  0.062706  0.213529 -0.009554   \n2017-11-16  0.008569  0.019059  0.023138  0.044631  0.078888  0.010391   \n2017-11-25  0.062763 -0.054391  0.026533  0.091086  0.180778 -0.015789   \n2018-01-15 -0.007286  0.000952  0.045509  0.031749  0.093047  0.015276   \n\n                 6         7         8         9    ...       290       291  \\\ndate                                                ...                       \n2017-07-07 -0.045367  0.011423 -0.063097 -0.038239  ...  0.047621 -0.016316   \n2017-10-16 -0.040246  0.040103 -0.138210 -0.035579  ...  0.057042 -0.011220   \n2017-11-16 -0.019623  0.029473 -0.034051 -0.047822  ...  0.002454 -0.043175   \n2017-11-25 -0.040906  0.025479 -0.018107 -0.039777  ...  0.056327  0.000679   \n2018-01-15 -0.007224  0.001105 -0.010089 -0.057663  ...  0.014419 -0.066990   \n\n                 292       293       294       295       296       297  \\\ndate                                                                     \n2017-07-07 -0.010944 -0.078619  0.008706  0.068910  0.028491  0.045232   \n2017-10-16 -0.074611 -0.137240  0.069290  0.134882  0.023557  0.088169   \n2017-11-16 -0.017312 -0.052432 -0.012902  0.017311 -0.023603  0.074907   \n2017-11-25 -0.038278 -0.007993  0.040597 -0.000809 -0.002990  0.077777   \n2018-01-15 -0.027252 -0.046227 -0.042189  0.029861 -0.007709  0.104993   \n\n                 298       299  \ndate                            \n2017-07-07 -0.024050  0.012990  \n2017-10-16 -0.077396 -0.003851  \n2017-11-16  0.008695  0.047033  \n2017-11-25 -0.034933 -0.075832  \n2018-01-15  0.013280  0.017047  \n\n[5 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-07-07</th>\n      <td>0.045714</td>\n      <td>-0.001961</td>\n      <td>0.025097</td>\n      <td>0.050116</td>\n      <td>0.124880</td>\n      <td>0.012416</td>\n      <td>-0.045367</td>\n      <td>0.011423</td>\n      <td>-0.063097</td>\n      <td>-0.038239</td>\n      <td>...</td>\n      <td>0.047621</td>\n      <td>-0.016316</td>\n      <td>-0.010944</td>\n      <td>-0.078619</td>\n      <td>0.008706</td>\n      <td>0.068910</td>\n      <td>0.028491</td>\n      <td>0.045232</td>\n      <td>-0.024050</td>\n      <td>0.012990</td>\n    </tr>\n    <tr>\n      <th>2017-10-16</th>\n      <td>0.056051</td>\n      <td>-0.048256</td>\n      <td>0.014275</td>\n      <td>0.062706</td>\n      <td>0.213529</td>\n      <td>-0.009554</td>\n      <td>-0.040246</td>\n      <td>0.040103</td>\n      <td>-0.138210</td>\n      <td>-0.035579</td>\n      <td>...</td>\n      <td>0.057042</td>\n      <td>-0.011220</td>\n      <td>-0.074611</td>\n      <td>-0.137240</td>\n      <td>0.069290</td>\n      <td>0.134882</td>\n      <td>0.023557</td>\n      <td>0.088169</td>\n      <td>-0.077396</td>\n      <td>-0.003851</td>\n    </tr>\n    <tr>\n      <th>2017-11-16</th>\n      <td>0.008569</td>\n      <td>0.019059</td>\n      <td>0.023138</td>\n      <td>0.044631</td>\n      <td>0.078888</td>\n      <td>0.010391</td>\n      <td>-0.019623</td>\n      <td>0.029473</td>\n      <td>-0.034051</td>\n      <td>-0.047822</td>\n      <td>...</td>\n      <td>0.002454</td>\n      <td>-0.043175</td>\n      <td>-0.017312</td>\n      <td>-0.052432</td>\n      <td>-0.012902</td>\n      <td>0.017311</td>\n      <td>-0.023603</td>\n      <td>0.074907</td>\n      <td>0.008695</td>\n      <td>0.047033</td>\n    </tr>\n    <tr>\n      <th>2017-11-25</th>\n      <td>0.062763</td>\n      <td>-0.054391</td>\n      <td>0.026533</td>\n      <td>0.091086</td>\n      <td>0.180778</td>\n      <td>-0.015789</td>\n      <td>-0.040906</td>\n      <td>0.025479</td>\n      <td>-0.018107</td>\n      <td>-0.039777</td>\n      <td>...</td>\n      <td>0.056327</td>\n      <td>0.000679</td>\n      <td>-0.038278</td>\n      <td>-0.007993</td>\n      <td>0.040597</td>\n      <td>-0.000809</td>\n      <td>-0.002990</td>\n      <td>0.077777</td>\n      <td>-0.034933</td>\n      <td>-0.075832</td>\n    </tr>\n    <tr>\n      <th>2018-01-15</th>\n      <td>-0.007286</td>\n      <td>0.000952</td>\n      <td>0.045509</td>\n      <td>0.031749</td>\n      <td>0.093047</td>\n      <td>0.015276</td>\n      <td>-0.007224</td>\n      <td>0.001105</td>\n      <td>-0.010089</td>\n      <td>-0.057663</td>\n      <td>...</td>\n      <td>0.014419</td>\n      <td>-0.066990</td>\n      <td>-0.027252</td>\n      <td>-0.046227</td>\n      <td>-0.042189</td>\n      <td>0.029861</td>\n      <td>-0.007709</td>\n      <td>0.104993</td>\n      <td>0.013280</td>\n      <td>0.017047</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#infer vector from every headline\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "df['vec'] = df.parallel_apply(lambda row: model.infer_vector(documents[row.name][0], steps=20), axis=1)\n",
    "#turn column of lists to columns (explode)\n",
    "df = pd.concat([pd.DataFrame(df['vec'].values.tolist()),df['date']],axis=1)\n",
    "#set data as index\n",
    "df.set_index('date', inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#read/write to csv\n",
    "\n",
    "# df.to_csv('./datasets/headline_vectors.csv')\n",
    "# df = pd.read_csv('./datasets/headline_vectors.csv', index_col='date', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huawei', 'to', 'offer', 'first', 'crypto', 'wallet', 'app', 'on', 'latest', 'smartphones'] 0.8514715433120728\n",
      "['coinjar', 'first', 'bitcoin', 'app', 'to', 'reemerge', 'on', 'iphone', 'app_store'] 0.6404440999031067\n",
      "['tesla', 'will_be', 'the', 'next', 'amazon', 'unless', 'it', 'gets', 'acquired_by', 'apple', 'first'] 0.5720335245132446\n",
      "['opera', 'to', 'launch', 'first', 'browser', 'with', 'native', 'crypto', 'wallet'] 0.5637149214744568\n",
      "['usdx', 'wallet', 'announces', 'integration', 'with', 'first', 'crypto', 'exchange', 'exmarkets'] 0.5604363679885864\n"
     ]
    }
   ],
   "source": [
    "example=60000\n",
    "tmp = documents[example][0]\n",
    "vector = model.infer_vector(tmp)\n",
    "most_sim = model.docvecs.most_similar([vector], topn=5)\n",
    "for (sent, score) in [(documents[most_sim[i][0]].words, most_sim[i][1]) for i in range(len(most_sim))]: print(sent, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: ['bitcoin', 'is', 'a', 'good', 'investment']\n",
      "[(10496, 0.868197500705719), (3277, 0.8647539019584656), (9353, 0.8615254163742065), (3189, 0.8604573011398315), (2082, 0.8598318099975586)]\n"
     ]
    }
   ],
   "source": [
    "example1=['bitcoin', 'is','a','good','investment']\n",
    "print('Example 1: ' + str(example1))\n",
    "vector = model.infer_vector(example1, steps=10)\n",
    "most_sim = model.docvecs.most_similar([vector], topn=5)\n",
    "print(most_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ptyxiaki",
   "language": "python",
   "name": "ptyxiaki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}